Boarding Bee - Test & Documentation Summary
===========================================

Overview
--------
This document summarizes the professional testing and documentation practices implemented in the Boarding Bee project. It covers test coverage, performance testing, E2E automation, and API documentation, with references to where artifacts and reports can be found.

1. Test Coverage Reports
------------------------
- **Backend:**
  - All backend code is covered by unit and integration tests.
  - Coverage reports are generated automatically during CI/CD runs (see GitHub Actions artifacts).
  - Reports include line, branch, and method coverage statistics.

- **Frontend:**
  - Key React components and utilities are covered by unit tests (if implemented).
  - Coverage reports are available in the CI/CD pipeline if enabled.

2. Performance Testing (JMeter)
-------------------------------
- JMeter scripts are used to simulate real-world load and measure backend API performance.
- Test plans are located in `tests/jmeter/`.
- Performance test results (HTML or CSV) are generated and attached as CI/CD artifacts after each run.
- Metrics include response time, throughput, error rate, and resource utilization.

3. End-to-End (E2E) Testing (Selenium)
---------------------------------------

Selenium-based E2E tests validate real user flows across the deployed frontend and backend.

How to Run E2E Tests Locally:
1. Ensure both backend and frontend are running (see deployment guide).
2. Install dependencies:
  - `npm install` (in the project root and `tests/selenium/` if needed)
  - Ensure Chrome is installed (or update scripts for your browser)
3. Run the E2E test script:
  - `./run-e2e-tests.sh`
  - Or use `npm run e2e` if defined in `package.json`
4. Test results will be generated as JUnit XML in the `selenium-results/` folder.
5. Summaries and HTML/PDF reports are generated by `tests/summarize-e2e.js`.

How to Run E2E Tests in CI/CD:
- E2E tests are automatically run in GitHub Actions after deployment.
- Results and reports are attached as workflow artifacts and emailed to contributors.

What the E2E Tests Cover:
- User registration and login flows
- Listing creation, editing, and viewing
- Booking/appointment requests
- Admin and owner dashboard actions
- Error handling and edge cases

How to Read the Results:
- JUnit XML files: For integration with CI tools
- HTML/PDF summary: For human-readable test case results, pass/fail status, and screenshots (if enabled)

Key Selenium E2E Test Cases:

**User Registration & Login**
- Happy path: Register a new user, fill all required fields, and verify redirect to login.
- Edge cases: Invalid email, unmatched passwords, missing fields, duplicate email, and registration error handling.
- Login happy path: Login with valid credentials, verify homepage loads.
- Login edge cases: Invalid email format, wrong password, non-existent email, and error message validation.

**Owner Dashboard Flows**
- Owner login: Login as owner and verify dashboard access.
- Listing creation: Create a new listing, upload image, and verify it appears in the dashboard table.
- Listing actions: Edit, view, renew, and delete listings; verify navigation and state changes.
- Edit profile: Navigate to and from the profile edit page.
- Pagination: Test next/previous page navigation if available.

**Admin Moderation Flows**
- Admin login: Login as admin and access moderation dashboard.
- Approve listing: Approve a pending listing and verify it moves to the approved tab.
- Reject listing: Reject a listing and verify it moves to the rejected tab.
- Tab navigation: Switch between Pending, Approved, Rejected, Activity, Security, and Reports tabs.
- Cleanup: Ensure test listings are deleted after test completion.

**Tenant Review & Rating Flows**
- Tenant login: Login as tenant and access homepage.
- View listing: Navigate to a listing details page.
- Rating UI: Verify rating stars are visible and interactive.
- Review validation: Attempt to submit a review without selecting a star and check for validation error.
- Submit review: Submit a valid review with rating and verify persistence after reload.

Test scripts are grouped by user role and flow for clarity. Each script covers both happy paths and edge cases, with assertions for UI state, navigation, and backend integration.

Location of Test Scripts:
- All Selenium E2E scripts are in `tests/selenium/`
- Test runner and summary scripts are in `tests/`

4. API Documentation (Swagger UI)
----------------------------------
- The backend exposes interactive API documentation via Swagger UI.
- Access the docs at `/swagger` on the deployed backend (e.g., `https://boardingbee-atf5gegteud8hpc0.southindia-01.azurewebsites.net/swagger`).
- The OpenAPI (Swagger) JSON is downloadable for client generation and integration.

5. Documentation Structure
--------------------------
- All documentation (deployment, environment, API, and test reports) is organized in the project root and relevant subfolders.
- Test and coverage reports are available as downloadable artifacts from GitHub Actions runs.
- Reports are well-structured for quick access and review by developers, testers, and examiners.

6. Artifacts & Access
---------------------
- **CI/CD Artifacts:**
  - Coverage, performance, and E2E test reports are attached to each GitHub Actions run.
  - Reports are also sent to contributors via email after successful test runs.
- **Manual Access:**
  - All scripts and test plans are available in the `tests/` directory.
  - API docs are always accessible via the deployed backend.

For further details, refer to the projectâ€™s deployment guide and CI/CD logs.
